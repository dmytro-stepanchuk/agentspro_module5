"""
–ú–£–õ–¨–¢–ò–ê–ì–ï–ù–¢–ù–ê –°–ò–°–¢–ï–ú–ê - LangGraph 1.0 Supervisor Pattern
–†–æ–∑—à–∏—Ä–µ–Ω–Ω—è –∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü—ñ—î—é –∫—ñ–ª—å–∫–æ—Ö —Å–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∏—Ö –∞–≥–µ–Ω—Ç—ñ–≤

Architecture:
- SupervisorAgent: –ö–æ–æ—Ä–¥–∏–Ω—É—î –∫–æ–º–∞–Ω–¥—É –∞–≥–µ–Ω—Ç—ñ–≤
- ResearcherVectorAgent: Vector search –≤ knowledge base (NEW!)
- ResearcherWebAgent: Web search —á–µ—Ä–µ–∑ Tavily (NEW!)
- AnalyzerAgent: –ê–Ω–∞–ª—ñ–∑ –∑–Ω–∞–π–¥–µ–Ω–æ—ó —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó
- SynthesizerAgent: –°–∏–Ω—Ç–µ–∑ —Ñ—ñ–Ω–∞–ª—å–Ω–æ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
- CriticAgent: –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ

LangSmith Integration: –¢—Ä–µ–π—Å–∏–Ω–≥ –≤—Å—ñ—Ö –∞–≥–µ–Ω—Ç—ñ–≤ —Ç–∞ —ó—Ö –≤–∑–∞—î–º–æ–¥—ñ—ó
"""

import os
from typing import TypedDict, Annotated, Literal, List
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.documents import Document
from langchain_community.vectorstores import FAISS
from langchain_community.tools.tavily_search import TavilySearchResults
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel, Field
from dotenv import load_dotenv
import operator

load_dotenv()

# ============================================================================
# LANGSMITH VERIFICATION
# ============================================================================

if os.getenv("LANGCHAIN_TRACING_V2") == "true":
    print("OK LangSmith —Ç—Ä–µ–π—Å–∏–Ω–≥ –∞–∫—Ç–∏–≤–Ω–∏–π –¥–ª—è –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ—ó —Å–∏—Å—Ç–µ–º–∏")
    print(f"Stats: Project: {os.getenv('LANGCHAIN_PROJECT', 'default')}\n")
else:
    print("WARNING  LangSmith –Ω–µ –≤–≤—ñ–º–∫–Ω–µ–Ω–∏–π\n")


# ============================================================================
# STATE DEFINITION - Shared state –¥–ª—è –≤—Å—ñ—Ö –∞–≥–µ–Ω—Ç—ñ–≤
# ============================================================================

class MultiAgentState(TypedDict):
    """
    –°–ø—ñ–ª—å–Ω–∏–π state –¥–ª—è –≤—Å—ñ—î—ó –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ—ó —Å–∏—Å—Ç–µ–º–∏

    –í–∫–ª—é—á–∞—î:
    - messages: —ñ—Å—Ç–æ—Ä—ñ—è –∫–æ–º—É–Ω—ñ–∫–∞—Ü—ñ—ó –º—ñ–∂ –∞–≥–µ–Ω—Ç–∞–º–∏
    - question: –ø–æ—á–∞—Ç–∫–æ–≤–µ –ø–∏—Ç–∞–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    - current_agent: —è–∫–∏–π –∞–≥–µ–Ω—Ç –∑–∞—Ä–∞–∑ –∞–∫—Ç–∏–≤–Ω–∏–π
    - vector_docs: –¥–æ–∫—É–º–µ–Ω—Ç–∏ –∑ vector search (NEW!)
    - web_docs: –¥–æ–∫—É–º–µ–Ω—Ç–∏ –∑ web search (NEW!)
    - retrieved_docs: –æ–±'—î–¥–Ω–∞–Ω—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏ –¥–ª—è Analyzer
    - analysis: —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª—ñ–∑—É (AnalyzerAgent)
    - final_answer: —Ñ—ñ–Ω–∞–ª—å–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å (SynthesizerAgent)
    - supervisor_decision: —Ä—ñ—à–µ–Ω–Ω—è supervisor –ø—Ä–æ –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫
    - iteration_count: –ª—ñ—á–∏–ª—å–Ω–∏–∫ —ñ—Ç–µ—Ä–∞—Ü—ñ–π
    - critic_score: –æ—Ü—ñ–Ω–∫–∞ –≤—ñ–¥ critic (1-10)
    - critic_feedback: feedback –≤—ñ–¥ critic
    - revision_count: –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–µ–≤—ñ–∑—ñ–π
    - research_complete: —á–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –æ–±–∏–¥–≤–∞ researcher (NEW!)
    """
    messages: Annotated[List, operator.add]  # –î–æ–¥–∞–≤–∞–Ω–Ω—è –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
    question: str
    current_agent: str
    # NEW: Separate storage for parallel researchers
    vector_docs: List[Document]
    web_docs: List[Document]
    retrieved_docs: List[Document]  # Combined docs for analyzer
    analysis: str
    final_answer: str
    supervisor_decision: str
    iteration_count: int
    # Critic fields
    critic_score: int
    critic_feedback: str
    revision_count: int
    # NEW: Track research completion
    research_complete: bool


# ============================================================================
# KNOWLEDGE BASE - LangGraph 1.0 Documentation
# ============================================================================

# –°—Ç–≤–æ—Ä—é—î–º–æ knowledge base –∑ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—î—é –ø—Ä–æ LangGraph 1.0
documents = [
    Document(
        page_content="""LangGraph 1.0 Supervisor Pattern:
        Hierarchical multi-agent architecture where a central supervisor agent coordinates multiple specialized agents.
        The supervisor receives user input, delegates work to sub-agents based on their capabilities,
        and when sub-agents respond, control returns to the supervisor. Each agent maintains its own scratchpad
        while the supervisor orchestrates communication and task delegation. This pattern is ideal for complex
        workflows requiring specialized expertise.""",
        metadata={"source": "supervisor_pattern", "version": "1.0"}
    ),
    Document(
        page_content="""LangGraph StateGraph API:
        StateGraph is the core abstraction for building multi-agent systems in LangGraph 1.0.
        It maintains centralized state storing intermediate results and metadata. Agents are represented as nodes,
        connections as edges. Control flow is managed by edges with conditional routing.
        StateGraph enables parallel execution, conditional branching, and state persistence through checkpointing.
        Key methods: add_node(), add_edge(), add_conditional_edges(), compile().""",
        metadata={"source": "stategraph_api", "version": "1.0"}
    ),
    Document(
        page_content="""LangGraph Checkpointing Mechanisms:
        LangGraph 1.0 provides persistent state storage through checkpointing. MemorySaver for development,
        PostgresSaver/SqliteSaver for production. Checkpoints enable time-travel through execution states,
        rollback to prior points, and replay workflows with adjusted parameters. Each checkpoint is identified
        by thread_id allowing separate conversation sessions. Prevents state corruption and ensures data integrity.
        Checkpoint memory is managed using threads for isolation.""",
        metadata={"source": "checkpointing", "version": "1.0"}
    ),
    Document(
        page_content="""LangGraph Multi-Agent Coordination:
        Agent coordination patterns in LangGraph 1.0 include: 1) Supervisor Pattern - central coordinator,
        2) Hierarchical Teams - nested supervision layers, 3) Network Pattern - peer-to-peer communication.
        State management handles agent communication through shared StateGraph. Each agent reads/writes to state.
        Communication via messages in state. Output consolidation through final synthesis node.
        Guardrails via conditional routing and validation nodes.""",
        metadata={"source": "coordination", "version": "1.0"}
    ),
    Document(
        page_content="""LangGraph Swarm (2025 Release):
        New lightweight library for swarm-style multi-agent systems. Maintains shared state with conversation history
        and active_agent marker. Uses checkpointer (in-memory or database) to persist state across turns.
        Aims to make multi-agent coordination easier and more reliable. Provides abstractions to link individual
        LLM agents into one integrated application. Emphasizes state management and checkpointing for reliability.
        Supports parallel agent execution with conflict resolution.""",
        metadata={"source": "swarm", "version": "1.0"}
    ),
    Document(
        page_content="""LangGraph Server & Persistence:
        LangGraph 1.0 includes LangGraph Server for production deployments. Provides comprehensive persistence:
        stores checkpoints, memories, thread metadata, and assistant configurations. Enables distributed multi-agent
        systems with API endpoints. Supports horizontal scaling. Built-in monitoring and observability.
        Integration with LangSmith for tracing all agents. REST API for agent invocation and state inspection.
        Webhook support for async workflows.""",
        metadata={"source": "server", "version": "1.0"}
    ),
    Document(
        page_content="""LangGraph Error Handling & Recovery:
        Multi-agent systems in LangGraph 1.0 include robust error handling. Each node can handle exceptions gracefully.
        Conditional edges for error routing. Retry mechanisms with exponential backoff. Circuit breakers to prevent
        cascade failures. State rollback on errors using checkpoints. Validation nodes before critical operations.
        Supervisor can reassign tasks if agent fails. Timeout handling at node level.
        Error messages propagated through state.""",
        metadata={"source": "error_handling", "version": "1.0"}
    ),
    Document(
        page_content="""LangGraph Best Practices for Multi-Agent Systems:
        1) Define clear agent responsibilities and capabilities. 2) Use supervisor for complex coordination.
        3) Implement checkpointing for long-running workflows. 4) Add validation nodes between critical steps.
        5) Use conditional edges for dynamic routing. 6) Keep state schema simple and typed.
        7) Implement timeouts for all agent operations. 8) Use LangSmith for observability.
        9) Test each agent independently before integration. 10) Design for agent failure and recovery.""",
        metadata={"source": "best_practices", "version": "1.0"}
    ),
]

print(f"KB: Knowledge Base: {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ –ø—Ä–æ LangGraph 1.0\n")

# ============================================================================
# VECTOR STORE SETUP
# ============================================================================

embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
vectorstore = FAISS.from_documents(documents, embeddings)
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3}  # –¢–æ–ø-3 –¥–æ–∫—É–º–µ–Ω—Ç–∏
)

print("OK Vector store –≥–æ—Ç–æ–≤–∏–π (FAISS)\n")

# ============================================================================
# TAVILY WEB SEARCH SETUP
# ============================================================================

tavily_available = False
tavily_search = None

if os.getenv("TAVILY_API_KEY"):
    tavily_search = TavilySearchResults(max_results=3)
    tavily_available = True
    print("OK Tavily web search –≥–æ—Ç–æ–≤–∏–π\n")
else:
    print("WARNING  TAVILY_API_KEY –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∏–π - web search –±—É–¥–µ —Å–∏–º—É–ª—å–æ–≤–∞–Ω–∏–π\n")

# ============================================================================
# LLM SETUP
# ============================================================================

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# ============================================================================
# PYDANTIC MODELS –¥–ª—è structured output
# ============================================================================

class SupervisorDecision(BaseModel):
    """–†—ñ—à–µ–Ω–Ω—è supervisor –∞–≥–µ–Ω—Ç–∞ –ø—Ä–æ –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫"""
    next_agent: Literal["research", "analyzer", "synthesizer", "critic", "FINISH"] = Field(
        description="–Ø–∫–∏–π –∞–≥–µ–Ω—Ç –º–∞—î –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏ –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ –∞–±–æ FINISH"
    )
    reasoning: str = Field(description="–ü–æ—è—Å–Ω–µ–Ω–Ω—è —á–æ–º—É –æ–±—Ä–∞–Ω–æ —Ü—å–æ–≥–æ –∞–≥–µ–Ω—Ç–∞")


class ResearchQuality(BaseModel):
    """–û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ –∑–Ω–∞–π–¥–µ–Ω–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤"""
    is_sufficient: bool = Field(description="–ß–∏ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –∑–Ω–∞–π–¥–µ–Ω–æ")
    confidence: float = Field(description="–í–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å –≤ —è–∫–æ—Å—Ç—ñ (0.0-1.0)")
    reasoning: str = Field(description="–û–±“ë—Ä—É–Ω—Ç—É–≤–∞–Ω–Ω—è –æ—Ü—ñ–Ω–∫–∏")


class CriticEvaluation(BaseModel):
    """–û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –≤—ñ–¥ Critic –∞–≥–µ–Ω—Ç–∞"""
    accuracy_score: int = Field(description="–û—Ü—ñ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç—ñ (1-10)", ge=1, le=10)
    completeness_score: int = Field(description="–û—Ü—ñ–Ω–∫–∞ –ø–æ–≤–Ω–æ—Ç–∏ (1-10)", ge=1, le=10)
    readability_score: int = Field(description="–û—Ü—ñ–Ω–∫–∞ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—ñ (1-10)", ge=1, le=10)
    overall_score: int = Field(description="–ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ (1-10)", ge=1, le=10)
    feedback: str = Field(description="–î–µ—Ç–∞–ª—å–Ω–∏–π feedback –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ")
    needs_revision: bool = Field(description="–ß–∏ –ø–æ—Ç—Ä—ñ–±–Ω–∞ —Ä–µ–≤—ñ–∑—ñ—è (True —è–∫—â–æ overall_score < 7)")


# ============================================================================
# AGENT NODES - –°–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –∞–≥–µ–Ω—Ç–∏
# ============================================================================

def supervisor_node(state: MultiAgentState) -> MultiAgentState:
    """
    SupervisorAgent: –ö–æ–æ—Ä–¥–∏–Ω—É—î –∫–æ–º–∞–Ω–¥—É –∞–≥–µ–Ω—Ç—ñ–≤

    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω—É –ª–æ–≥—ñ–∫—É –¥–ª—è routing
    """
    print("\n" + "="*70)
    print("SUPERVISOR SUPERVISOR AGENT: –ü—Ä–∏–π–º–∞—î —Ä—ñ—à–µ–Ω–Ω—è –ø—Ä–æ –¥–µ–ª–µ–≥—É–≤–∞–Ω–Ω—è")
    print("="*70)

    iteration = state.get("iteration_count", 0) + 1
    question = state["question"]

    # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –ø–æ—Ç–æ—á–Ω–∏–π —Å—Ç–∞–Ω
    research_complete = state.get("research_complete", False)
    has_docs = bool(state.get("retrieved_docs"))
    has_analysis = bool(state.get("analysis"))
    has_answer = bool(state.get("final_answer"))
    critic_score = state.get("critic_score", 0)
    revision_count = state.get("revision_count", 0)

    print(f"Stats: Iteration: {iteration}")
    print(f"üìù Question: {question}")
    print(f"üîç Research complete: {research_complete}")
    print(f"KB: Docs combined: {has_docs}")
    print(f"RESEARCHER Analysis done: {has_analysis}")
    print(f"OK Answer ready: {has_answer}")
    print(f"‚≠ê Critic score: {critic_score}")
    print(f"üîÑ Revisions: {revision_count}")

    # DETERMINISTIC ROUTING
    if not research_complete:
        next_agent = "research"
        reasoning = "Need to run parallel research (vector + web search)"
    elif not has_analysis:
        next_agent = "analyzer"
        reasoning = "Research complete, need to analyze combined results"
    elif not has_answer:
        next_agent = "synthesizer"
        reasoning = "Analysis ready, need to create answer"
    elif critic_score == 0:
        next_agent = "critic"
        reasoning = "Answer ready but not evaluated yet, need critic review"
    elif critic_score >= 7:
        next_agent = "FINISH"
        reasoning = f"Answer approved with score {critic_score}/10"
    elif revision_count >= 2:
        next_agent = "FINISH"
        reasoning = f"Max revisions reached ({revision_count}), finalizing with score {critic_score}/10"
    else:
        next_agent = "synthesizer"
        reasoning = f"Score {critic_score}/10 < 7, revision {revision_count + 1} needed"

    print(f"\nSUPERVISOR Decision: {next_agent}")
    print(f"üí≠ Reasoning: {reasoning}\n")

    return {
        **state,
        "current_agent": next_agent,
        "supervisor_decision": reasoning,
        "iteration_count": iteration,
        "messages": [AIMessage(content=f"Supervisor ‚Üí {next_agent}: {reasoning}")]
    }


def researcher_vector_node(state: MultiAgentState) -> MultiAgentState:
    """
    ResearcherVectorAgent: Vector search –≤ knowledge base

    –í–∏–∫–æ–Ω—É—î—Ç—å—Å—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ –∑ researcher_web_node
    """
    print("\n" + "="*70)
    print("üìö RESEARCHER VECTOR: –ü–æ—à—É–∫ –≤ knowledge base")
    print("="*70)

    question = state["question"]

    # –í–∏–∫–æ–Ω—É—î–º–æ vector search
    vector_docs = retriever.invoke(question)

    print(f"KB: –ó–Ω–∞–π–¥–µ–Ω–æ {len(vector_docs)} –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ –∑ vector store")
    for i, doc in enumerate(vector_docs, 1):
        print(f"  {i}. {doc.metadata.get('source', 'unknown')}: {doc.page_content[:80]}...")

    return {
        **state,
        "vector_docs": vector_docs,
        "messages": [AIMessage(content=f"ResearcherVector: Found {len(vector_docs)} docs from knowledge base")]
    }


def researcher_web_node(state: MultiAgentState) -> MultiAgentState:
    """
    ResearcherWebAgent: Web search —á–µ—Ä–µ–∑ Tavily

    –í–∏–∫–æ–Ω—É—î—Ç—å—Å—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ –∑ researcher_vector_node
    """
    print("\n" + "="*70)
    print("üåê RESEARCHER WEB: Web search —á–µ—Ä–µ–∑ Tavily")
    print("="*70)

    question = state["question"]
    web_docs = []

    if tavily_available and tavily_search:
        try:
            # –í–∏–∫–æ–Ω—É—î–º–æ web search
            search_results = tavily_search.invoke(question)

            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤ Documents
            for result in search_results:
                content = result.get("content", "")
                url = result.get("url", "")
                web_docs.append(Document(
                    page_content=content,
                    metadata={"source": "web_search", "url": url}
                ))

            print(f"üåê –ó–Ω–∞–π–¥–µ–Ω–æ {len(web_docs)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∑ web")
            for i, doc in enumerate(web_docs, 1):
                print(f"  {i}. {doc.metadata.get('url', 'unknown')[:50]}...")
                print(f"     {doc.page_content[:80]}...")

        except Exception as e:
            print(f"WARNING  Web search error: {e}")
            # Fallback: —Å–∏–º—É–ª—é—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
            web_docs = [
                Document(
                    page_content=f"Web search result about LangGraph: Modern framework for building stateful AI agents with support for cycles, controllability, and persistence.",
                    metadata={"source": "web_search", "url": "https://langchain-ai.github.io/langgraph/"}
                )
            ]
    else:
        # –°–∏–º—É–ª—é—î–º–æ web search —è–∫—â–æ Tavily –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π
        print("‚ö†Ô∏è  Tavily –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Å–∏–º—É–ª—å–æ–≤–∞–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏")
        web_docs = [
            Document(
                page_content=f"Simulated web result: LangGraph is a library for building stateful, multi-actor applications with LLMs. It extends LangChain Expression Language with cyclic computational capabilities.",
                metadata={"source": "web_search_simulated", "url": "https://example.com/langgraph"}
            ),
            Document(
                page_content=f"Simulated web result: LangGraph enables complex agent architectures including supervisor patterns, hierarchical teams, and network topologies for multi-agent coordination.",
                metadata={"source": "web_search_simulated", "url": "https://example.com/langgraph-patterns"}
            )
        ]
        print(f"üåê –°–∏–º—É–ª—å–æ–≤–∞–Ω–æ {len(web_docs)} web —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")

    return {
        **state,
        "web_docs": web_docs,
        "messages": [AIMessage(content=f"ResearcherWeb: Found {len(web_docs)} docs from web search")]
    }


def combine_research_node(state: MultiAgentState) -> MultiAgentState:
    """
    –û–±'—î–¥–Ω—É—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –≤—ñ–¥ –æ–±–æ—Ö researcher agents

    –ó–∞–ø—É—Å–∫–∞—î—Ç—å—Å—è –ø—ñ—Å–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ–≥–æ –ø–æ—à—É–∫—É
    """
    print("\n" + "="*70)
    print("üîó COMBINE RESEARCH: –û–±'—î–¥–Ω–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")
    print("="*70)

    vector_docs = state.get("vector_docs", [])
    web_docs = state.get("web_docs", [])

    # –û–±'—î–¥–Ω—É—î–º–æ –¥–æ–∫—É–º–µ–Ω—Ç–∏
    combined_docs = vector_docs + web_docs

    print(f"üìö Vector docs: {len(vector_docs)}")
    print(f"üåê Web docs: {len(web_docs)}")
    print(f"üìä Total combined: {len(combined_docs)}")

    return {
        **state,
        "retrieved_docs": combined_docs,
        "research_complete": True,
        "messages": [AIMessage(content=f"CombineResearch: Combined {len(combined_docs)} docs ({len(vector_docs)} vector + {len(web_docs)} web)")]
    }


def analyzer_node(state: MultiAgentState) -> MultiAgentState:
    """
    AnalyzerAgent: –ê–Ω–∞–ª—ñ–∑—É—î –∑–Ω–∞–π–¥–µ–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –∑ –æ–±–æ—Ö –¥–∂–µ—Ä–µ–ª
    """
    print("\n" + "="*70)
    print("ANALYZER ANALYZER AGENT: –ê–Ω–∞–ª—ñ–∑—É—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é")
    print("="*70)

    question = state["question"]
    docs = state.get("retrieved_docs", [])

    if not docs:
        print("WARNING  No documents to analyze")
        return {
            **state,
            "analysis": "No documents found for analysis",
            "messages": [AIMessage(content="Analyzer: No documents to analyze")]
        }

    # –†–æ–∑–¥—ñ–ª—è—î–º–æ –¥–æ–∫—É–º–µ–Ω—Ç–∏ –∑–∞ –¥–∂–µ—Ä–µ–ª–æ–º –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
    vector_count = len([d for d in docs if d.metadata.get("source") != "web_search" and d.metadata.get("source") != "web_search_simulated"])
    web_count = len(docs) - vector_count

    # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –¥–æ–∫—É–º–µ–Ω—Ç–∏
    newline = chr(10)
    docs_text = newline.join([
        f"{i+1}. Source: {doc.metadata.get('source', 'unknown')}{newline}{doc.page_content}{newline}"
        for i, doc in enumerate(docs)
    ])

    analysis_prompt = f"""Analyze the following documents from TWO sources and extract key insights.

Question: {question}

Documents ({vector_count} from knowledge base, {web_count} from web search):
{docs_text}

Provide a structured analysis with:
1. Key concepts found (note which source)
2. Relevant patterns/architectures
3. Best practices mentioned
4. Specific technical details
5. How web results complement or validate knowledge base info"""

    messages = [
        SystemMessage(content="You are an expert technical analyst specializing in LangGraph and multi-agent systems. You analyze information from multiple sources."),
        HumanMessage(content=analysis_prompt)
    ]

    response = llm.invoke(messages)
    analysis = response.content

    print(f"Stats: Analysis:\n{analysis[:300]}...\n")

    return {
        **state,
        "analysis": analysis,
        "messages": [AIMessage(content=f"Analyzer: Completed analysis ({len(analysis)} chars) from {len(docs)} docs")]
    }


def synthesizer_node(state: MultiAgentState) -> MultiAgentState:
    """
    SynthesizerAgent: –°–∏–Ω—Ç–µ–∑—É—î —Ñ—ñ–Ω–∞–ª—å–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å
    """
    print("\n" + "="*70)
    print("SYNTHESIZER SYNTHESIZER AGENT: –°—Ç–≤–æ—Ä—é—î —Ñ—ñ–Ω–∞–ª—å–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å")
    print("="*70)

    question = state["question"]
    analysis = state.get("analysis", "")
    docs = state.get("retrieved_docs", [])
    critic_feedback = state.get("critic_feedback", "")
    revision_count = state.get("revision_count", 0)

    # –Ø–∫—â–æ —î feedback –≤—ñ–¥ critic - —Ü–µ —Ä–µ–≤—ñ–∑—ñ—è
    if critic_feedback and revision_count > 0:
        print(f"üîÑ Revision #{revision_count} based on critic feedback")

        synthesis_prompt = f"""REVISION REQUESTED: Improve the answer based on critic feedback.

Question: {question}

Previous Answer:
{state.get('final_answer', '')}

Critic Feedback:
{critic_feedback}

Analysis:
{analysis}

Create an IMPROVED answer that:
1. Addresses ALL points in the critic feedback
2. Maintains accuracy and completeness
3. Improves readability and structure
4. Keeps the same core information but presents it better"""

    else:
        # –ü–µ—Ä—à–∏–π —Å–∏–Ω—Ç–µ–∑
        synthesis_prompt = f"""Create a comprehensive, well-structured answer based on analysis from multiple sources.

Question: {question}

Analysis:
{analysis}

Source Documents:
{chr(10).join([f"- {doc.metadata.get('source', 'unknown')}" for doc in docs])}

Create a clear, informative answer that:
1. Directly addresses the question
2. Incorporates insights from BOTH knowledge base and web sources
3. Provides specific technical details
4. Includes examples where relevant
5. Notes where different sources agree or complement each other"""

    messages = [
        SystemMessage(content="You are an expert technical writer creating clear, comprehensive answers from multiple sources."),
        HumanMessage(content=synthesis_prompt)
    ]

    response = llm.invoke(messages)
    final_answer = response.content

    print(f"OK Final Answer:\n{final_answer[:300]}...\n")

    return {
        **state,
        "final_answer": final_answer,
        "messages": [AIMessage(content=f"Synthesizer: {'Revised' if revision_count > 0 else 'Created'} answer ({len(final_answer)} chars)")]
    }


def critic_node(state: MultiAgentState) -> MultiAgentState:
    """
    CriticAgent: –û—Ü—ñ–Ω—é—î —è–∫—ñ—Å—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ –≤—ñ–¥ Synthesizer
    """
    print("\n" + "="*70)
    print("‚≠ê CRITIC AGENT: –û—Ü—ñ–Ω—é—î —è–∫—ñ—Å—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ")
    print("="*70)

    question = state["question"]
    answer = state.get("final_answer", "")
    analysis = state.get("analysis", "")
    revision_count = state.get("revision_count", 0)

    if not answer:
        print("WARNING  No answer to evaluate")
        return {
            **state,
            "critic_score": 0,
            "critic_feedback": "No answer provided",
            "messages": [AIMessage(content="Critic: No answer to evaluate")]
        }

    # –û—Ü—ñ–Ω—é—î–º–æ –≤—ñ–¥–ø–æ–≤—ñ–¥—å
    critic_prompt = f"""You are a strict but fair critic evaluating the quality of an AI-generated answer.

Question: {question}

Answer to evaluate:
{answer}

Reference Analysis (ground truth):
{analysis}

Evaluate the answer on three criteria (1-10 scale):

1. ACCURACY (1-10): Does the answer contain correct information? Is it factually accurate based on the analysis?
2. COMPLETENESS (1-10): Does it cover all important aspects mentioned in the analysis? Are there gaps?
3. READABILITY (1-10): Is it well-structured, clear, and easy to understand?

Calculate OVERALL score as the average of the three scores.

If overall_score < 7, the answer needs revision. Provide specific, actionable feedback.
If overall_score >= 7, the answer is acceptable.

Be critical but constructive. Focus on specific improvements needed."""

    messages = [
        SystemMessage(content="You are an expert technical reviewer with high standards for quality."),
        HumanMessage(content=critic_prompt)
    ]

    # –û—Ç—Ä–∏–º—É—î–º–æ structured evaluation
    structured_llm = llm.with_structured_output(CriticEvaluation)
    evaluation = structured_llm.invoke(messages)

    print(f"\nüìä Evaluation Results:")
    print(f"  - Accuracy:     {evaluation.accuracy_score}/10")
    print(f"  - Completeness: {evaluation.completeness_score}/10")
    print(f"  - Readability:  {evaluation.readability_score}/10")
    print(f"  - OVERALL:      {evaluation.overall_score}/10")
    print(f"\nüí≠ Feedback: {evaluation.feedback[:200]}...")
    print(f"\nüîÑ Needs revision: {evaluation.needs_revision}")

    # –û–Ω–æ–≤–ª—é—î–º–æ revision_count —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–∞ —Ä–µ–≤—ñ–∑—ñ—è
    new_revision_count = revision_count + 1 if evaluation.needs_revision else revision_count

    return {
        **state,
        "critic_score": evaluation.overall_score,
        "critic_feedback": evaluation.feedback,
        "revision_count": new_revision_count,
        "messages": [AIMessage(content=f"Critic: Score {evaluation.overall_score}/10 {'(needs revision)' if evaluation.needs_revision else '(approved)'}")]
    }


# ============================================================================
# ROUTING LOGIC - –£–º–æ–≤–Ω–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü—ñ—è
# ============================================================================

def route_after_supervisor(state: MultiAgentState) -> str:
    """–í–∏–∑–Ω–∞—á–∞—î –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∫—Ä–æ–∫ –ø—ñ—Å–ª—è supervisor"""
    decision = state.get("current_agent", "research")

    if decision == "FINISH":
        return "end"
    elif decision == "research":
        return "research"
    elif decision == "analyzer":
        return "analyzer"
    elif decision == "synthesizer":
        return "synthesizer"
    elif decision == "critic":
        return "critic"
    else:
        return "end"


# ============================================================================
# GRAPH CONSTRUCTION - –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∏–π workflow –∑ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–∏–º –ø–æ—à—É–∫–æ–º
# ============================================================================

def create_multiagent_system():
    """
    –°—Ç–≤–æ—Ä—é—î –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—É —Å–∏—Å—Ç–µ–º—É –∑ Supervisor Pattern —Ç–∞ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–∏–º –ø–æ—à—É–∫–æ–º

    Architecture:
    START ‚Üí Supervisor ‚Üí [ResearcherVector ‚Üí ResearcherWeb] ‚Üí Combine ‚Üí Supervisor ‚Üí Analyzer ‚Üí ...
    """
    print("=" * 70)
    print("BUILDING  –°–¢–í–û–†–ï–ù–ù–Ø –ú–£–õ–¨–¢–ò–ê–ì–ï–ù–¢–ù–û–á –°–ò–°–¢–ï–ú–ò")
    print("=" * 70 + "\n")

    # –°—Ç–≤–æ—Ä—é—î–º–æ StateGraph
    workflow = StateGraph(MultiAgentState)

    # –î–æ–¥–∞—î–º–æ –∞–≥–µ–Ω—Ç—ñ–≤ —è–∫ nodes
    workflow.add_node("supervisor", supervisor_node)
    workflow.add_node("researcher_vector", researcher_vector_node)
    workflow.add_node("researcher_web", researcher_web_node)
    workflow.add_node("combine_research", combine_research_node)
    workflow.add_node("analyzer", analyzer_node)
    workflow.add_node("synthesizer", synthesizer_node)
    workflow.add_node("critic", critic_node)

    # –í—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ entry point
    workflow.set_entry_point("supervisor")

    # Conditional edges –≤—ñ–¥ supervisor
    workflow.add_conditional_edges(
        "supervisor",
        route_after_supervisor,
        {
            "research": "researcher_vector",  # Start parallel research
            "analyzer": "analyzer",
            "synthesizer": "synthesizer",
            "critic": "critic",
            "end": END
        }
    )

    # –ü–∞—Ä–∞–ª–µ–ª—å–Ω–µ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: vector -> web -> combine
    workflow.add_edge("researcher_vector", "researcher_web")
    workflow.add_edge("researcher_web", "combine_research")

    # –ü—ñ—Å–ª—è combine –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ—Å—å –¥–æ supervisor
    workflow.add_edge("combine_research", "supervisor")

    # –Ü–Ω—à—ñ –∞–≥–µ–Ω—Ç–∏ –ø–æ–≤–µ—Ä—Ç–∞—é—Ç—å—Å—è –¥–æ supervisor
    workflow.add_edge("analyzer", "supervisor")
    workflow.add_edge("synthesizer", "supervisor")
    workflow.add_edge("critic", "supervisor")

    # –ö–æ–º–ø—ñ–ª—é—î–º–æ –∑ checkpointer
    checkpointer = MemorySaver()
    app = workflow.compile(checkpointer=checkpointer)

    print("OK –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ —Å—Ç–≤–æ—Ä–µ–Ω–∞\n")
    print("Agents:")
    print("  SUPERVISOR Supervisor - –∫–æ–æ—Ä–¥–∏–Ω—É—î –∫–æ–º–∞–Ω–¥—É")
    print("  üìö ResearcherVector - vector search –≤ knowledge base (NEW!)")
    print("  üåê ResearcherWeb - web search —á–µ—Ä–µ–∑ Tavily (NEW!)")
    print("  üîó CombineResearch - –æ–±'—î–¥–Ω–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ (NEW!)")
    print("  ANALYZER Analyzer - –∞–Ω–∞–ª—ñ–∑ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó")
    print("  SYNTHESIZER Synthesizer - —Å–∏–Ω—Ç–µ–∑ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ")
    print("  ‚≠ê Critic - –æ—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ\n")
    print("Research Flow:")
    print("  Supervisor ‚Üí ResearcherVector ‚Üí ResearcherWeb ‚Üí Combine ‚Üí Supervisor\n")

    return app


# ============================================================================
# TESTING - –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ—ó —Å–∏—Å—Ç–µ–º–∏
# ============================================================================

def test_multiagent_system():
    """–¢–µ—Å—Ç—É—î –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—É —Å–∏—Å—Ç–µ–º—É –∑ —Ä—ñ–∑–Ω–∏–º–∏ –∑–∞–ø–∏—Ç–∞–º–∏"""

    app = create_multiagent_system()

    test_queries = [
        "What is the Supervisor Pattern in LangGraph 1.0 and how does it work?",
        "Explain LangGraph StateGraph API and checkpointing mechanisms",
        "How do multi-agent coordination patterns work in LangGraph 1.0?",
    ]

    for i, query in enumerate(test_queries, 1):
        print("\n" + "=" * 70)
        print(f"TEST {i}: {query}")
        print("=" * 70)

        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ state
        initial_state = {
            "messages": [],
            "question": query,
            "current_agent": "supervisor",
            "vector_docs": [],
            "web_docs": [],
            "retrieved_docs": [],
            "analysis": "",
            "final_answer": "",
            "supervisor_decision": "",
            "iteration_count": 0,
            "critic_score": 0,
            "critic_feedback": "",
            "revision_count": 0,
            "research_complete": False
        }

        # –í–∏–∫–æ–Ω—É—î–º–æ –∑ checkpointing
        config = {"configurable": {"thread_id": f"test_{i}"}}

        try:
            # Stream —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
            for event in app.stream(initial_state, config):
                agent_name = list(event.keys())[0]
                print(f"\nüìç Event from: {agent_name}")

            # –û—Ç—Ä–∏–º—É—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π state
            final_state = app.get_state(config)

            print("\n" + "-" * 70)
            print("Stats: FINAL RESULT")
            print("-" * 70)
            print(f"\nSUPERVISOR Question: {query}\n")
            print(f"OK Answer:\n{final_state.values.get('final_answer', 'No answer')}\n")
            print(f"üìà Stats:")
            print(f"  - Iterations: {final_state.values.get('iteration_count', 0)}")
            print(f"  - Vector docs: {len(final_state.values.get('vector_docs', []))}")
            print(f"  - Web docs: {len(final_state.values.get('web_docs', []))}")
            print(f"  - Total docs: {len(final_state.values.get('retrieved_docs', []))}")
            print(f"  - Messages exchanged: {len(final_state.values.get('messages', []))}")
            print(f"  - Critic score: {final_state.values.get('critic_score', 0)}/10")
            print(f"  - Revisions made: {final_state.values.get('revision_count', 0)}")

        except Exception as e:
            print(f"\n‚ùå Error: {e}")
            import traceback
            traceback.print_exc()

        if i < len(test_queries):
            input("\n‚è∏Ô∏è  Press Enter to continue to next test...\n")


# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    print("\n")
    print("SUPERVISOR LangGraph 1.0 - Multi-Agent System (Parallel Research)")
    print("=" * 70)
    print()
    print("Features:")
    print("  OK Supervisor Pattern - hierarchical coordination")
    print("  OK 6 Specialized Agents + Combine node")
    print("  üìö NEW: ResearcherVector - vector search in knowledge base")
    print("  üåê NEW: ResearcherWeb - web search via Tavily")
    print("  üîó NEW: CombineResearch - merge results from both sources")
    print("  OK StateGraph - centralized state management")
    print("  OK Checkpointing - persistent state with MemorySaver")
    print("  OK Conditional Routing - dynamic agent selection")
    print("  OK LangSmith Tracing - full observability")
    print("  ‚≠ê Critic Agent - answer quality evaluation")
    print("  üîÑ Revision Loop - max 2 revisions if score < 7")
    print()
    print("=" * 70 + "\n")

    if not os.getenv("OPENAI_API_KEY"):
        print("‚ùå ERROR: OPENAI_API_KEY not found!")
        exit(1)

    try:
        test_multiagent_system()

        print("\n" + "=" * 70)
        print("OK ALL TESTS COMPLETED")
        print("=" * 70)
        print("\nüí° Check LangSmith dashboard for full trace!")
        print("   https://smith.langchain.com/\n")

    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  Tests interrupted")
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()